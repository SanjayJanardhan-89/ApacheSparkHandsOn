{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/pRgMEL8QUuXYjJcuhoM1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayJanardhan-89/ApacheSparkHandsOn/blob/main/ComplexDatatypes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "QLc7s-Qo1irp",
        "outputId": "60be0a00-b757-4fe2-f13d-478958a799ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,678 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,692 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,763 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,237 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,962 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,003 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,535 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [112 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [38.5 kB]\n",
            "Fetched 24.4 MB in 7s (3,663 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "30 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7cb4eca3fb90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4db6950c80a6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>OurSparkApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"OurSparkApp\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import col\n"
      ],
      "metadata": {
        "id": "JcL3W7AK4_jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Arrays**"
      ],
      "metadata": {
        "id": "QUuzueIAcXPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sql_array = spark.sql(\"SELECT array('KGF 1', 'KGF 2', 'Autograph', 'Kicha','Hucha') as movies\")\n",
        "df_sql_array.printSchema()\n",
        "df_sql_array.show(truncate=False)"
      ],
      "metadata": {
        "id": "NDhHyKMo5Q4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9a0fe8-5e2a-4be4-8e33-ed655b611502"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- movies: array (nullable = false)\n",
            " |    |-- element: string (containsNull = false)\n",
            "\n",
            "+---------------------------------------+\n",
            "|movies                                 |\n",
            "+---------------------------------------+\n",
            "|[KGF 1, KGF 2, Autograph, Kicha, Hucha]|\n",
            "+---------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, ArrayType,MapType\n",
        "\n",
        "data = [\n",
        "          [\n",
        "            [\"KGF 1\", \"KGF 2\", \"Autograph\", \"Kicha\",\"Hucha\"]\n",
        "          ]\n",
        "        ]\n",
        "\n",
        "# Schema\n",
        "schema = StructType([\n",
        "             StructField('movies', ArrayType(StringType()), True),\n",
        "     ])\n",
        "\n",
        "# Create DataFrame\n",
        "df_array = spark.createDataFrame(data = data, schema = schema)\n",
        "df_array.printSchema()\n",
        "df_array.show(truncate=False) # shows all columns"
      ],
      "metadata": {
        "id": "KRnw_ETEci45",
        "outputId": "3d61b7f2-1651-4049-9de9-81065b17eadb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- movies: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+---------------------------------------+\n",
            "|movies                                 |\n",
            "+---------------------------------------+\n",
            "|[KGF 1, KGF 2, Autograph, Kicha, Hucha]|\n",
            "+---------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Map type**"
      ],
      "metadata": {
        "id": "FtiiHCUffA9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sql_map = spark.sql(\"SELECT map('Building','500 CR', 'Commercal',100) as income\")\n",
        "df_sql_map.printSchema()\n",
        "df_sql_map.show(truncate=False)"
      ],
      "metadata": {
        "id": "PpgJZQiUfJA3",
        "outputId": "aecd7037-6294-4dd5-da2e-c464636bb7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- income: map (nullable = false)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = false)\n",
            "\n",
            "+--------------------------------------+\n",
            "|income                                |\n",
            "+--------------------------------------+\n",
            "|{Building -> 500 CR, Commercal -> 100}|\n",
            "+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, ArrayType,MapType\n",
        "\n",
        "\n",
        "data = [\n",
        "\n",
        "          ({\"Bank\":\"100 CR\", \"Business\":\"50 CR\", \"Land\":\"150 CR\"}),\n",
        "          # ({\"Others\":\"300 CR\"}),\n",
        "          # ({\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "          # ({\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "\n",
        "      ]\n",
        "\n",
        "\n",
        "# Schema\n",
        "schema = StructType([\n",
        "               StructField('properties', MapType(StringType(),StringType()), True)\n",
        "        ])\n",
        "\n",
        "# Create DataFrame\n",
        "df_map = spark.createDataFrame(data = data, schema = schema)\n",
        "df_map.printSchema()\n",
        "df_map.show(truncate=False) # shows all columns"
      ],
      "metadata": {
        "id": "vL_8teOyfpC4",
        "outputId": "f2f1b7cc-edf9-4adb-d616-53816327a532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+---------------------------------------------------+\n",
            "|properties                                         |\n",
            "+---------------------------------------------------+\n",
            "|{Bank -> 100 CR, Land -> 150 CR, Business -> 50 CR}|\n",
            "+---------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|spark.sql(\"SELECT struct(1, 2, 3) as ex_struct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77On1brROzSI",
        "outputId": "11a8b49c-d290-4289-9972-b8180310fcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[ex_struct: struct<col1:int,col2:int,col3:int>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_struct = spark.sql(\"SELECT struct(1, 2, '3') as ex_struct\")\n",
        "df_struct.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACGJLu9-NjKw",
        "outputId": "266cc7c4-a284-47da-8a16-b17910862ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|ex_struct|\n",
            "+---------+\n",
            "|{1, 2, 3}|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_struct.select(\"ex_struct.col3\", \"ex_struct\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B46JwCaePajw",
        "outputId": "82ce3755-9e13-404d-897c-a0c22551a2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|col3|ex_struct|\n",
            "+----+---------+\n",
            "|   3|{1, 2, 3}|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_struct.select(\"ex_struct.*\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeMsLV5Qdbp9",
        "outputId": "4a03e2d9-f573-4e65-f05f-57e597d116d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|1   |2   |3   |\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_map = spark.sql(\"SELECT map(1.0, '2', 3.0, '4') as ex_map\")\n",
        "df_map.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-Dl2Y1DOSd3",
        "outputId": "b1195e4e-834a-40f3-e646-3f8e06500f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|              ex_map|\n",
            "+--------------------+\n",
            "|{1.0 -> 2, 3.0 -> 4}|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, ArrayType,MapType\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "# Data\n",
        "data = [\n",
        "        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
        "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
        "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
        "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
        "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
        "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
        "        ]\n",
        "\n",
        "# Schema\n",
        "schema = StructType([\n",
        "    StructField('name', StructType([\n",
        "         StructField('firstname', StringType(), True),\n",
        "         StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "         ])),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        "     ])\n",
        "\n",
        "# Create DataFrame\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False) # shows all columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jye_i4rTOfIk",
        "outputId": "bbe0fdec-6e59-4576-ce1f-863553ac0384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+-----+------+\n",
            "|name                  |state|gender|\n",
            "+----------------------+-----+------+\n",
            "|{James, NULL, Smith}  |OH   |M     |\n",
            "|{Anna, Rose, }        |NY   |F     |\n",
            "|{Julia, , Williams}   |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |NY   |M     |\n",
            "|{Mike, Mary, Williams}|OH   |M     |\n",
            "+----------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.select(\"name\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLx1sLW0ctrH",
        "outputId": "6fdd982d-97ec-4db7-c198-c55727ce70ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                name|\n",
            "+--------------------+\n",
            "|{James, NULL, Smith}|\n",
            "|      {Anna, Rose, }|\n",
            "| {Julia, , Williams}|\n",
            "|{Maria, Anne, Jones}|\n",
            "|  {Jen, Mary, Brown}|\n",
            "|{Mike, Mary, Will...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, ArrayType,MapType\n",
        "from pyspark.sql.functions import element_at\n",
        "\n",
        "data = [\n",
        "        ([(\"Yash\",\"K\",None),(\"Yash2\",\"K2\",None)],\"BL\",\"M\",[\"KGF 1\", \"KGF 2\"],{\"Bank\":\"100 CR\", \"Business\":\"50 CR\", \"Land\":\"150 CR\"}),\n",
        "        ([(\"Sudeep\",\"Kicha\",\"S\")],\"DL\",\"M\",[\"Autograph\", \"Kicha\",\"Hucha\"],{\"Others\":\"300 CR\"}),\n",
        "        ([(\"Puneeth\",None,\"Raj\")],\"MB\",\"M\",[], {\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "        ([(\"Darshan\",None,None)],\"MB\",\"M\",[], {\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "\n",
        "        ]\n",
        "\n",
        "# Schema\n",
        "schema = StructType([\n",
        "    StructField(    'name'\n",
        "                  , ArrayType(\n",
        "                        StructType([\n",
        "                            StructField('firstname', StringType(), True),\n",
        "                            StructField('middlename', StringType(), True),\n",
        "                            StructField('lastname', StringType(), True)\n",
        "                        ])\n",
        "                    ), True),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True),\n",
        "     StructField('movies', ArrayType(StringType()), True),\n",
        "     StructField('properties', MapType(StringType(),StringType()), True)\n",
        "     ])\n",
        "\n",
        "# Create DataFrame\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False) # shows all columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJwWwq4Xc-0Z",
        "outputId": "468e11f5-95f8-4a03-80a4-102964f61988"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- firstname: string (nullable = true)\n",
            " |    |    |-- middlename: string (nullable = true)\n",
            " |    |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- movies: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+------------------------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "|name                                |state|gender|movies                   |properties                                         |\n",
            "+------------------------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "|[{Yash, K, NULL}, {Yash2, K2, NULL}]|BL   |M     |[KGF 1, KGF 2]           |{Bank -> 100 CR, Land -> 150 CR, Business -> 50 CR}|\n",
            "|[{Sudeep, Kicha, S}]                |DL   |M     |[Autograph, Kicha, Hucha]|{Others -> 300 CR}                                 |\n",
            "|[{Puneeth, NULL, Raj}]              |MB   |M     |[]                       |{Building -> 500 CR, Commercal -> 100}             |\n",
            "|[{Darshan, NULL, NULL}]             |MB   |M     |[]                       |{Building -> 500 CR, Commercal -> 100}             |\n",
            "+------------------------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " (df2\n",
        "  .select(\"properties\", \"name\", \"name.firstname\")\n",
        "  .withColumn(\"M-Building\", col(\"properties\").getItem(\"Building\"))\n",
        "  .withColumn(\"M-Commercal \", col(\"properties\").getItem(\"Commercal\"))\n",
        "  .withColumn(\"M-Others \", col(\"properties\").getItem(\"Others\"))\n",
        "  .withColumn(\"S-FName\", col(\"name.firstname\"))\n",
        "  ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0-Z3EjP0njz",
        "outputId": "a6e04d9a-3bb8-48f6-9dcd-8a7d9bd219a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------+----------+------------+---------+-------+\n",
            "|          properties|                name|firstname|M-Building|M-Commercal |M-Others |S-FName|\n",
            "+--------------------+--------------------+---------+----------+------------+---------+-------+\n",
            "|{Bank -> 100 CR, ...|     {Yash, K, NULL}|     Yash|      NULL|        NULL|     NULL|   Yash|\n",
            "|  {Others -> 300 CR}|  {Sudeep, Kicha, S}|   Sudeep|      NULL|        NULL|   300 CR| Sudeep|\n",
            "|{Building -> 500 ...|{Puneeth, NULL, Raj}|  Puneeth|    500 CR|         100|     NULL|Puneeth|\n",
            "|{Building -> 500 ...|{Darshan, NULL, N...|  Darshan|    500 CR|         100|     NULL|Darshan|\n",
            "+--------------------+--------------------+---------+----------+------------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, ArrayType,MapType\n",
        "from pyspark.sql.functions import element_at\n",
        "\n",
        "data = [\n",
        "        ((\"Yash\",\"K\",None),\"BL\",\"M\",[\"KGF 1\", \"KGF 2\"],{\"Bank\":\"100 CR\", \"Business\":\"50 CR\", \"Land\":\"150 CR\"}),\n",
        "        ((\"Sudeep\",\"Kicha\",\"S\"),\"DL\",\"M\",[\"Autograph\", \"Kicha\",\"Hucha\"],{\"Others\":\"300 CR\"}),\n",
        "        ((\"Puneeth\",None,\"Raj\"),\"MB\",\"M\",[], {\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "        ((\"Darshan\",None,None),\"MB\",\"M\",[], {\"Building\":\"500 CR\", \"Commercal\":100}),\n",
        "\n",
        "        ]\n",
        "\n",
        "# Schema\n",
        "schema = StructType([\n",
        "    StructField('name', StructType([\n",
        "         StructField('firstname', StringType(), True),\n",
        "         StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "         ])),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True),\n",
        "     StructField('movies', ArrayType(StringType()), True),\n",
        "     StructField('properties', MapType(StringType(),StringType()), True)\n",
        "     ])\n",
        "\n",
        "# Create DataFrame\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False) # shows all columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QiMme632DET",
        "outputId": "22e1ec1c-594b-473b-b950-2f87e1b7e29c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- movies: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+---------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "|name                 |state|gender|movies                   |properties                                         |\n",
            "+---------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "|{Yash, K, NULL}      |BL   |M     |[KGF 1, KGF 2]           |{Bank -> 100 CR, Land -> 150 CR, Business -> 50 CR}|\n",
            "|{Sudeep, Kicha, S}   |DL   |M     |[Autograph, Kicha, Hucha]|{Others -> 300 CR}                                 |\n",
            "|{Puneeth, NULL, Raj} |MB   |M     |[]                       |{Building -> 500 CR, Commercal -> 100}             |\n",
            "|{Darshan, NULL, NULL}|MB   |M     |[]                       |{Building -> 500 CR, Commercal -> 100}             |\n",
            "+---------------------+-----+------+-------------------------+---------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
        "\n",
        "myManualSchema = StructType([\n",
        "  StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
        "  StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
        "  StructField(\"count\", LongType(), False, metadata={\"hello\":\"world\"})\n",
        "])\n",
        "df = spark.read.format(\"json\").schema(myManualSchema)\\\n",
        "  .load(\"sample_data/2015-summary.json\")"
      ],
      "metadata": {
        "id": "21WEGU2v8_tA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "VbyGAHMHa87-",
        "outputId": "636dffe0-9497-4b73-ce00-50629a8eb01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-----+\n",
            "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
            "+--------------------+-------------------+-----+\n",
            "|       United States|            Romania|   15|\n",
            "|       United States|            Croatia|    1|\n",
            "|       United States|            Ireland|  344|\n",
            "|               Egypt|      United States|   15|\n",
            "|       United States|              India|   62|\n",
            "|       United States|          Singapore|    1|\n",
            "|       United States|            Grenada|   62|\n",
            "|          Costa Rica|      United States|  588|\n",
            "|             Senegal|      United States|   40|\n",
            "|             Moldova|      United States|    1|\n",
            "|       United States|       Sint Maarten|  325|\n",
            "|       United States|   Marshall Islands|   39|\n",
            "|              Guyana|      United States|   64|\n",
            "|               Malta|      United States|    1|\n",
            "|            Anguilla|      United States|   41|\n",
            "|             Bolivia|      United States|   30|\n",
            "|       United States|           Paraguay|    6|\n",
            "|             Algeria|      United States|    4|\n",
            "|Turks and Caicos ...|      United States|  230|\n",
            "|       United States|          Gibraltar|    1|\n",
            "+--------------------+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "mcGnKSvKbQSR",
        "outputId": "42ba3405-038e-4bcd-fb0b-92de2fa18373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
            " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
            " |-- count: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"json\").load(\"sample_data/2015-summary.json\").schema"
      ],
      "metadata": {
        "id": "vC1GYIlfbT9m",
        "outputId": "0e7f09ed-fa95-454d-f2dc-168a6a8eaac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', LongType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.pr"
      ],
      "metadata": {
        "id": "JrUN61QqbhC3",
        "outputId": "b7cdb66a-f42b-4765-dd96-83362262ea9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'StructType' object has no attribute 'printSchema'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9f5e7f0815c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'StructType' object has no attribute 'printSchema'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXW2sWGcbmTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}