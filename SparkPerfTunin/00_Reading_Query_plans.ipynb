{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayJanardhan-89/ApacheSparkHandsOn/blob/main/SparkPerfTunin/00_Reading_Query_plans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WuOZ0C0lhCL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Pyspark\n"
      ],
      "metadata": {
        "id": "vRYFGd5ehHN5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "QLc7s-Qo1irp",
        "outputId": "ea91fbf6-7c7b-404e-a208-ac754dc4a546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,695 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,842 kB]\n",
            "Fetched 22.2 MB in 7s (2,979 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78bf6d75d490>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://36b2a51bf784:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>OurSparkApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"OurSparkApp\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data = [(\"John\", \"Field-eng\", 3500),\n",
        "    (\"Michael\", \"Field-eng\", 4500),\n",
        "    (\"Robert\", None, 4000),\n",
        "    (\"Maria\", \"Finance\", 3500),\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Kelly\", \"Finance\", 3500),\n",
        "    (\"Kate\", \"Finance\", 3000),\n",
        "    (\"Martin\", None, 3500),\n",
        "    (\"Kiran\", \"Sales\", 2200),\n",
        "    (\"Michael\", \"Field-eng\", 4500)\n",
        "  ]\n",
        "columns= [\"Employee\", \"Department\", \"Salary\"]\n",
        "salary_data = spark.createDataFrame(data = salary_data, schema = columns)\n",
        "salary_data.printSchema()\n",
        "salary_data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJlW3-06VvhB",
        "outputId": "0028591c-19bb-4d90-ea57-28d2d4e32691"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+--------+----------+------+\n",
            "|Employee|Department|Salary|\n",
            "+--------+----------+------+\n",
            "|    John| Field-eng|  3500|\n",
            "| Michael| Field-eng|  4500|\n",
            "|  Robert|      NULL|  4000|\n",
            "|   Maria|   Finance|  3500|\n",
            "|    John|     Sales|  3000|\n",
            "|   Kelly|   Finance|  3500|\n",
            "|    Kate|   Finance|  3000|\n",
            "|  Martin|      NULL|  3500|\n",
            "|   Kiran|     Sales|  2200|\n",
            "| Michael| Field-eng|  4500|\n",
            "+--------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3rrRipLVwMf",
        "outputId": "f6f7a3e9-cbbc-4732-c145-9ae3ace8e751"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.coalesce(1).explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZBfCvVnV2Ml",
        "outputId": "599faee8-40c8-42e2-a429-63f1a5940e58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "Employee: string, Department: string, Salary: bigint\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 1\n",
            "+- *(1) Scan ExistingRDD[Employee#0,Department#1,Salary#2L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Download CSV file\n",
        "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/hw_25000.csv\"\n",
        "csv_path = \"/tmp/hw_200.csv\"\n",
        "\n",
        "with open(csv_path, \"wb\") as f:\n",
        "    f.write(requests.get(url).content)\n",
        "\n",
        "df = spark.read.option(\"header\", True).csv(csv_path)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFSrZo6nYP7c",
        "outputId": "d0b6acdd-ae46-479b-fb6b-db9bd070c2f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+-----------------+\n",
            "|Index| \"Height(Inches)\"| \"Weight(Pounds)\"|\n",
            "+-----+-----------------+-----------------+\n",
            "|    1|         65.78331|         112.9925|\n",
            "|    2|         71.51521|         136.4873|\n",
            "|    3|         69.39874|         153.0269|\n",
            "|    4|          68.2166|         142.3354|\n",
            "|    5|         67.78781|         144.2971|\n",
            "+-----+-----------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoKgc-jhYmSZ",
        "outputId": "49e7e023-799f-455a-a584-1a77f94e0482"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.coalesce(1).explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UNRVFseYrEP",
        "outputId": "26b3c7fd-512b-41a0-a044-9538eca36e31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "Employee: string, Department: string, Salary: bigint\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 1\n",
            "+- *(1) Scan ExistingRDD[Employee#0,Department#1,Salary#2L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"csv\").options(header=\"True\").load(\"/assessments.csv\")"
      ],
      "metadata": {
        "id": "RHYfpT0Ebsnh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4r9IwM7czkI",
        "outputId": "572b4322-3fdb-49fc-9fae-c67a4d1dcec1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "|code_module|code_presentation|id_assessment|assessment_type|date|weight|\n",
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "|        AAA|            2013J|         1752|            TMA|  19|    10|\n",
            "|        AAA|            2013J|         1753|            TMA|  54|    20|\n",
            "|        AAA|            2013J|         1754|            TMA| 117|    20|\n",
            "|        AAA|            2013J|         1755|            TMA| 166|    20|\n",
            "|        AAA|            2013J|         1756|            TMA| 215|    30|\n",
            "|        AAA|            2013J|         1757|           Exam|NULL|   100|\n",
            "|        AAA|            2014J|         1758|            TMA|  19|    10|\n",
            "|        AAA|            2014J|         1759|            TMA|  54|    20|\n",
            "|        AAA|            2014J|         1760|            TMA| 117|    20|\n",
            "|        AAA|            2014J|         1761|            TMA| 166|    20|\n",
            "|        AAA|            2014J|         1762|            TMA| 215|    30|\n",
            "|        AAA|            2014J|         1763|           Exam|NULL|   100|\n",
            "|        BBB|            2013B|        14991|            CMA|  54|     1|\n",
            "|        BBB|            2013B|        14992|            CMA|  89|     1|\n",
            "|        BBB|            2013B|        14993|            CMA| 124|     1|\n",
            "|        BBB|            2013B|        14994|            CMA| 159|     1|\n",
            "|        BBB|            2013B|        14995|            CMA| 187|     1|\n",
            "|        BBB|            2013B|        14984|            TMA|  19|     5|\n",
            "|        BBB|            2013B|        14985|            TMA|  47|    18|\n",
            "|        BBB|            2013B|        14986|            TMA|  89|    18|\n",
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXnarMMmc25j",
        "outputId": "4f7f9f05-ef56-4f34-b5c2-7dcfc5cd332e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.coalesce(2).explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SAGLP6jdORk",
        "outputId": "c433445c-b0b0-47b0-dfa4-26333aac1b0c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "code_module: string, code_presentation: string, id_assessment: string, assessment_type: string, date: string, weight: string\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 2\n",
            "+- FileScan csv [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/assessments.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<code_module:string,code_presentation:string,id_assessment:string,assessment_type:string,da...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(10)\n",
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qPW7gBIdQqj",
        "outputId": "17359acc-6996-4bd8-de69-3564f855ca88"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_studentAssessment=spark.read.format(\"csv\").options(header=\"True\").load(\"/studentAssessment.csv\")\n",
        "df_stud_info=spark.read.format(\"csv\").options(header=\"True\").load(\"/studentInfo.csv\")"
      ],
      "metadata": {
        "id": "W5uqu_90dV-7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_studentAssessment.show(5)\n",
        "df_stud_info.show(5)"
      ],
      "metadata": {
        "id": "liNABlEtd9Ya",
        "outputId": "728c7a72-75fa-413c-a574-afa2a989d286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+--------------+---------+-----+\n",
            "|id_assessment|id_student|date_submitted|is_banked|score|\n",
            "+-------------+----------+--------------+---------+-----+\n",
            "|         1752|     11391|            18|        0|   78|\n",
            "|         1752|     28400|            22|        0|   70|\n",
            "|         1752|     31604|            17|        0|   72|\n",
            "|         1752|     32885|            26|        0|   69|\n",
            "|         1752|     38053|            19|        0|   79|\n",
            "+-------------+----------+--------------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
            "|code_module|code_presentation|id_student|gender|              region|   highest_education|imd_band|age_band|num_of_prev_attempts|studied_credits|disability|final_result|\n",
            "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
            "|        AAA|            2013J|     11391|     M| East Anglian Region|    HE Qualification| 90-100%|    55<=|                   0|            240|         N|        Pass|\n",
            "|        AAA|            2013J|     28400|     F|            Scotland|    HE Qualification|  20-30%|   35-55|                   0|             60|         N|        Pass|\n",
            "|        AAA|            2013J|     30268|     F|North Western Region|A Level or Equiva...|  30-40%|   35-55|                   0|             60|         Y|   Withdrawn|\n",
            "|        AAA|            2013J|     31604|     F|   South East Region|A Level or Equiva...|  50-60%|   35-55|                   0|             60|         N|        Pass|\n",
            "|        AAA|            2013J|     32885|     F|West Midlands Region|  Lower Than A Level|  50-60%|    0-35|                   0|             60|         N|        Pass|\n",
            "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_stud_info.join(df_studentAssessment, on=\"id_student\")"
      ],
      "metadata": {
        "id": "0PrVkFlyd9V6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined.show(5)"
      ],
      "metadata": {
        "id": "CRWQZ1gIejW3",
        "outputId": "9124b591-cbbb-41b5-bdb3-d26a4c26f401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+-------------+--------------+---------+-----+\n",
            "|id_student|code_module|code_presentation|gender|              region|   highest_education|imd_band|age_band|num_of_prev_attempts|studied_credits|disability|final_result|id_assessment|date_submitted|is_banked|score|\n",
            "+----------+-----------+-----------------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+-------------+--------------+---------+-----+\n",
            "|     11391|        AAA|            2013J|     M| East Anglian Region|    HE Qualification| 90-100%|    55<=|                   0|            240|         N|        Pass|         1752|            18|        0|   78|\n",
            "|     28400|        AAA|            2013J|     F|            Scotland|    HE Qualification|  20-30%|   35-55|                   0|             60|         N|        Pass|         1752|            22|        0|   70|\n",
            "|     31604|        AAA|            2013J|     F|   South East Region|A Level or Equiva...|  50-60%|   35-55|                   0|             60|         N|        Pass|         1752|            17|        0|   72|\n",
            "|     32885|        AAA|            2013J|     F|West Midlands Region|  Lower Than A Level|  50-60%|    0-35|                   0|             60|         N|        Pass|         1752|            26|        0|   69|\n",
            "|     38053|        AAA|            2013J|     M|               Wales|A Level or Equiva...|  80-90%|   35-55|                   0|             60|         N|        Pass|         1752|            19|        0|   79|\n",
            "+----------+-----------+-----------------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+-------------+--------------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined.explain(True)"
      ],
      "metadata": {
        "id": "D1ef8ajCfZz5",
        "outputId": "4e9df693-2c06-48d1-f276-3b7b4d733101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [id_student])\n",
            ":- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "+- Relation [id_assessment#1060,id_student#1061,date_submitted#1062,is_banked#1063,score#1064] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "id_student: string, code_module: string, code_presentation: string, gender: string, region: string, highest_education: string, imd_band: string, age_band: string, num_of_prev_attempts: string, studied_credits: string, disability: string, final_result: string, id_assessment: string, date_submitted: string, is_banked: string, score: string\n",
            "Project [id_student#1089, code_module#1087, code_presentation#1088, gender#1090, region#1091, highest_education#1092, imd_band#1093, age_band#1094, num_of_prev_attempts#1095, studied_credits#1096, disability#1097, final_result#1098, id_assessment#1060, date_submitted#1062, is_banked#1063, score#1064]\n",
            "+- Join Inner, (id_student#1089 = id_student#1061)\n",
            "   :- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "   +- Relation [id_assessment#1060,id_student#1061,date_submitted#1062,is_banked#1063,score#1064] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [id_student#1089, code_module#1087, code_presentation#1088, gender#1090, region#1091, highest_education#1092, imd_band#1093, age_band#1094, num_of_prev_attempts#1095, studied_credits#1096, disability#1097, final_result#1098, id_assessment#1060, date_submitted#1062, is_banked#1063, score#1064]\n",
            "+- Join Inner, (id_student#1089 = id_student#1061)\n",
            "   :- Filter isnotnull(id_student#1089)\n",
            "   :  +- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "   +- Filter isnotnull(id_student#1061)\n",
            "      +- Relation [id_assessment#1060,id_student#1061,date_submitted#1062,is_banked#1063,score#1064] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [id_student#1089, code_module#1087, code_presentation#1088, gender#1090, region#1091, highest_education#1092, imd_band#1093, age_band#1094, num_of_prev_attempts#1095, studied_credits#1096, disability#1097, final_result#1098, id_assessment#1060, date_submitted#1062, is_banked#1063, score#1064]\n",
            "   +- BroadcastHashJoin [id_student#1089], [id_student#1061], Inner, BuildLeft, false\n",
            "      :- BroadcastExchange HashedRelationBroadcastMode(List(input[2, string, false]),false), [plan_id=685]\n",
            "      :  +- Filter isnotnull(id_student#1089)\n",
            "      :     +- FileScan csv [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] Batched: false, DataFilters: [isnotnull(id_student#1089)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/studentInfo.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student)], ReadSchema: struct<code_module:string,code_presentation:string,id_student:string,gender:string,region:string,...\n",
            "      +- Filter isnotnull(id_student#1061)\n",
            "         +- FileScan csv [id_assessment#1060,id_student#1061,date_submitted#1062,is_banked#1063,score#1064] Batched: false, DataFilters: [isnotnull(id_student#1061)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/studentAssessment.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student)], ReadSchema: struct<id_assessment:string,id_student:string,date_submitted:string,is_banked:string,score:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined.rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "XyKr6ibKfdQd",
        "outputId": "e8150716-1966-4f7a-e6e5-456912b43403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df_stud_info.groupBy(\"code_module\").count()).explain(True)"
      ],
      "metadata": {
        "id": "mJtOGC7rpvS4",
        "outputId": "1de808f4-2b6b-46ef-92af-ac66b32d1092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['code_module], ['code_module, count(1) AS count#1384L]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "code_module: string, count: bigint\n",
            "Aggregate [code_module#1087], [code_module#1087, count(1) AS count#1384L]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [code_module#1087], [code_module#1087, count(1) AS count#1384L]\n",
            "+- Project [code_module#1087]\n",
            "   +- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[code_module#1087], functions=[count(1)], output=[code_module#1087, count#1384L])\n",
            "   +- Exchange hashpartitioning(code_module#1087, 200), ENSURE_REQUIREMENTS, [plan_id=817]\n",
            "      +- HashAggregate(keys=[code_module#1087], functions=[partial_count(1)], output=[code_module#1087, count#1388L])\n",
            "         +- FileScan csv [code_module#1087] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/studentInfo.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<code_module:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stud_info.printSchema()"
      ],
      "metadata": {
        "id": "9hcXsG9QrQKb",
        "outputId": "dfa01fd3-5d97-4145-a5c7-5905381418de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- code_module: string (nullable = true)\n",
            " |-- code_presentation: string (nullable = true)\n",
            " |-- id_student: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- highest_education: string (nullable = true)\n",
            " |-- imd_band: string (nullable = true)\n",
            " |-- age_band: string (nullable = true)\n",
            " |-- num_of_prev_attempts: string (nullable = true)\n",
            " |-- studied_credits: string (nullable = true)\n",
            " |-- disability: string (nullable = true)\n",
            " |-- final_result: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, col\n",
        "\n",
        "(df_stud_info\n",
        "  .groupBy(\"code_module\")\n",
        "  .agg(count_distinct(col(\"count_distinct\").cast(\"int\")).alias(\"total attemt\") )\n",
        ").explain(True)\n"
      ],
      "metadata": {
        "id": "FEsbJyb0p9aL",
        "outputId": "bcc2087f-5142-403a-a558-a2a8570846b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['code_module], ['code_module, sum(cast('num_of_prev_attempts as int)) AS total attemt#1438]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "code_module: string, total attemt: bigint\n",
            "Aggregate [code_module#1087], [code_module#1087, sum(cast(num_of_prev_attempts#1095 as int)) AS total attemt#1438L]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [code_module#1087], [code_module#1087, sum(cast(num_of_prev_attempts#1095 as int)) AS total attemt#1438L]\n",
            "+- Project [code_module#1087, num_of_prev_attempts#1095]\n",
            "   +- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[code_module#1087], functions=[sum(cast(num_of_prev_attempts#1095 as int))], output=[code_module#1087, total attemt#1438L])\n",
            "   +- Exchange hashpartitioning(code_module#1087, 200), ENSURE_REQUIREMENTS, [plan_id=830]\n",
            "      +- HashAggregate(keys=[code_module#1087], functions=[partial_sum(cast(num_of_prev_attempts#1095 as int))], output=[code_module#1087, sum#1442L])\n",
            "         +- FileScan csv [code_module#1087,num_of_prev_attempts#1095] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/studentInfo.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<code_module:string,num_of_prev_attempts:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, col, count_distinct\n",
        "\n",
        "(df_stud_info\n",
        "  .groupBy(\"code_module\")\n",
        "  .agg(count_distinct(col(\"highest_education\").alias(\"total attemt\") ))\n",
        ").explain(True)"
      ],
      "metadata": {
        "id": "pEN__AIPrMqf",
        "outputId": "3ddbcf31-a389-41ef-bf92-111c200039ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['code_module], ['code_module, unresolvedalias('count(distinct 'highest_education AS total attemt#1474), None)]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "code_module: string, count(DISTINCT highest_education AS `total attemt`): bigint\n",
            "Aggregate [code_module#1087], [code_module#1087, count(distinct highest_education#1092) AS count(DISTINCT highest_education AS `total attemt`)#1476L]\n",
            "+- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [code_module#1087], [code_module#1087, count(distinct highest_education#1092) AS count(DISTINCT highest_education AS `total attemt`)#1476L]\n",
            "+- Project [code_module#1087, highest_education#1092]\n",
            "   +- Relation [code_module#1087,code_presentation#1088,id_student#1089,gender#1090,region#1091,highest_education#1092,imd_band#1093,age_band#1094,num_of_prev_attempts#1095,studied_credits#1096,disability#1097,final_result#1098] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[code_module#1087], functions=[count(distinct highest_education#1092)], output=[code_module#1087, count(DISTINCT highest_education AS `total attemt`)#1476L])\n",
            "   +- Exchange hashpartitioning(code_module#1087, 200), ENSURE_REQUIREMENTS, [plan_id=866]\n",
            "      +- HashAggregate(keys=[code_module#1087], functions=[partial_count(distinct highest_education#1092)], output=[code_module#1087, count#1481L])\n",
            "         +- HashAggregate(keys=[code_module#1087, highest_education#1092], functions=[], output=[code_module#1087, highest_education#1092])\n",
            "            +- Exchange hashpartitioning(code_module#1087, highest_education#1092, 200), ENSURE_REQUIREMENTS, [plan_id=862]\n",
            "               +- HashAggregate(keys=[code_module#1087, highest_education#1092], functions=[], output=[code_module#1087, highest_education#1092])\n",
            "                  +- FileScan csv [code_module#1087,highest_education#1092] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/studentInfo.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<code_module:string,highest_education:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfiUwnH6sEFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}