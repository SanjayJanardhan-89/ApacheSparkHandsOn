{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayJanardhan-89/ApacheSparkHandsOn/blob/main/SparkPerfTunin/00_Reading_Query_plans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WuOZ0C0lhCL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Pyspark\n"
      ],
      "metadata": {
        "id": "vRYFGd5ehHN5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "QLc7s-Qo1irp",
        "outputId": "ea91fbf6-7c7b-404e-a208-ac754dc4a546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,695 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,842 kB]\n",
            "Fetched 22.2 MB in 7s (2,979 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78bf6d75d490>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://36b2a51bf784:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>OurSparkApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"OurSparkApp\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data = [(\"John\", \"Field-eng\", 3500),\n",
        "    (\"Michael\", \"Field-eng\", 4500),\n",
        "    (\"Robert\", None, 4000),\n",
        "    (\"Maria\", \"Finance\", 3500),\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Kelly\", \"Finance\", 3500),\n",
        "    (\"Kate\", \"Finance\", 3000),\n",
        "    (\"Martin\", None, 3500),\n",
        "    (\"Kiran\", \"Sales\", 2200),\n",
        "    (\"Michael\", \"Field-eng\", 4500)\n",
        "  ]\n",
        "columns= [\"Employee\", \"Department\", \"Salary\"]\n",
        "salary_data = spark.createDataFrame(data = salary_data, schema = columns)\n",
        "salary_data.printSchema()\n",
        "salary_data.show()\n"
      ],
      "metadata": {
        "id": "FJlW3-06VvhB",
        "outputId": "0028591c-19bb-4d90-ea57-28d2d4e32691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+--------+----------+------+\n",
            "|Employee|Department|Salary|\n",
            "+--------+----------+------+\n",
            "|    John| Field-eng|  3500|\n",
            "| Michael| Field-eng|  4500|\n",
            "|  Robert|      NULL|  4000|\n",
            "|   Maria|   Finance|  3500|\n",
            "|    John|     Sales|  3000|\n",
            "|   Kelly|   Finance|  3500|\n",
            "|    Kate|   Finance|  3000|\n",
            "|  Martin|      NULL|  3500|\n",
            "|   Kiran|     Sales|  2200|\n",
            "| Michael| Field-eng|  4500|\n",
            "+--------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "j3rrRipLVwMf",
        "outputId": "f6f7a3e9-cbbc-4732-c145-9ae3ace8e751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.coalesce(1).explain(True)"
      ],
      "metadata": {
        "id": "pZBfCvVnV2Ml",
        "outputId": "599faee8-40c8-42e2-a429-63f1a5940e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "Employee: string, Department: string, Salary: bigint\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 1\n",
            "+- *(1) Scan ExistingRDD[Employee#0,Department#1,Salary#2L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Download CSV file\n",
        "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/hw_25000.csv\"\n",
        "csv_path = \"/tmp/hw_200.csv\"\n",
        "\n",
        "with open(csv_path, \"wb\") as f:\n",
        "    f.write(requests.get(url).content)\n",
        "\n",
        "df = spark.read.option(\"header\", True).csv(csv_path)\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "YFSrZo6nYP7c",
        "outputId": "d0b6acdd-ae46-479b-fb6b-db9bd070c2f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+-----------------+\n",
            "|Index| \"Height(Inches)\"| \"Weight(Pounds)\"|\n",
            "+-----+-----------------+-----------------+\n",
            "|    1|         65.78331|         112.9925|\n",
            "|    2|         71.51521|         136.4873|\n",
            "|    3|         69.39874|         153.0269|\n",
            "|    4|          68.2166|         142.3354|\n",
            "|    5|         67.78781|         144.2971|\n",
            "+-----+-----------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "DoKgc-jhYmSZ",
        "outputId": "49e7e023-799f-455a-a584-1a77f94e0482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_data.coalesce(1).explain(True)"
      ],
      "metadata": {
        "id": "5UNRVFseYrEP",
        "outputId": "26b3c7fd-512b-41a0-a044-9538eca36e31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "Employee: string, Department: string, Salary: bigint\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 1, false\n",
            "+- LogicalRDD [Employee#0, Department#1, Salary#2L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 1\n",
            "+- *(1) Scan ExistingRDD[Employee#0,Department#1,Salary#2L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"csv\").options(header=\"True\").load(\"/assessments.csv\")"
      ],
      "metadata": {
        "id": "RHYfpT0Ebsnh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "m4r9IwM7czkI",
        "outputId": "572b4322-3fdb-49fc-9fae-c67a4d1dcec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "|code_module|code_presentation|id_assessment|assessment_type|date|weight|\n",
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "|        AAA|            2013J|         1752|            TMA|  19|    10|\n",
            "|        AAA|            2013J|         1753|            TMA|  54|    20|\n",
            "|        AAA|            2013J|         1754|            TMA| 117|    20|\n",
            "|        AAA|            2013J|         1755|            TMA| 166|    20|\n",
            "|        AAA|            2013J|         1756|            TMA| 215|    30|\n",
            "|        AAA|            2013J|         1757|           Exam|NULL|   100|\n",
            "|        AAA|            2014J|         1758|            TMA|  19|    10|\n",
            "|        AAA|            2014J|         1759|            TMA|  54|    20|\n",
            "|        AAA|            2014J|         1760|            TMA| 117|    20|\n",
            "|        AAA|            2014J|         1761|            TMA| 166|    20|\n",
            "|        AAA|            2014J|         1762|            TMA| 215|    30|\n",
            "|        AAA|            2014J|         1763|           Exam|NULL|   100|\n",
            "|        BBB|            2013B|        14991|            CMA|  54|     1|\n",
            "|        BBB|            2013B|        14992|            CMA|  89|     1|\n",
            "|        BBB|            2013B|        14993|            CMA| 124|     1|\n",
            "|        BBB|            2013B|        14994|            CMA| 159|     1|\n",
            "|        BBB|            2013B|        14995|            CMA| 187|     1|\n",
            "|        BBB|            2013B|        14984|            TMA|  19|     5|\n",
            "|        BBB|            2013B|        14985|            TMA|  47|    18|\n",
            "|        BBB|            2013B|        14986|            TMA|  89|    18|\n",
            "+-----------+-----------------+-------------+---------------+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "SXnarMMmc25j",
        "outputId": "4f7f9f05-ef56-4f34-b5c2-7dcfc5cd332e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.coalesce(2).explain(True)"
      ],
      "metadata": {
        "id": "5SAGLP6jdORk",
        "outputId": "c433445c-b0b0-47b0-dfa4-26333aac1b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "code_module: string, code_presentation: string, id_assessment: string, assessment_type: string, date: string, weight: string\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Repartition 2, false\n",
            "+- Relation [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "Coalesce 2\n",
            "+- FileScan csv [code_module#292,code_presentation#293,id_assessment#294,assessment_type#295,date#296,weight#297] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/assessments.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<code_module:string,code_presentation:string,id_assessment:string,assessment_type:string,da...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(10)\n",
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "3qPW7gBIdQqj",
        "outputId": "17359acc-6996-4bd8-de69-3564f855ca88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W5uqu_90dV-7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}